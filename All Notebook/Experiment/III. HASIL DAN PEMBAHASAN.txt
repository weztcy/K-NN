III. HASIL DAN PEMBAHASAN
Pada bab ini, akan dijelaskan hasil yang diperoleh dari setiap tahapan yang telah dijelaskan pada bagian metode penelitian. Berikut adalah penjelasan mengenai hasil yang didapat dari proses yang telah dilakukan: 
A.	Preprocessing Data
Pada tahap awal preprocessing, dilakukan pemeriksaan terhadap tipe data untuk memastikan bahwa setiap fitur dalam dataset memiliki format yang sesuai. Dalam KNN, perhitungan jarak, seperti menggunakan Euclidean distance, bergantung pada angka yang dapat dihitung secara matematis. Oleh karena itu, jika dataset berisi data non-numerik, algoritma ini tidak akan dapat melakukan perhitungan jarak yang benar, sehingga dapat mempengaruhi akurasi hasil prediksi.

TABEL 2
TIPE DATA PADA SETIAP FITUR DATASET

Dari Tabel 2, dapat dilihat bahwa sebagian besar fitur memiliki tipe data int64, kecuali fitur BMI dan DiabetesPedigreeFunction yang bertipe float64. Meskipun terdapat perbedaan antara int64 dan float64, kedua tipe data tersebut tetap termasuk dalam kategori numerik dan dapat diproses oleh algoritma KNN tanpa memerlukan konversi tipe data tambahan.
Pada tahap selanjutnya dalam preprocessing, dilakukan pemeriksaan terhadap missing values dan data duplikat. Jika ditemukan data yang memiliki missing values, data tersebut akan dihapus untuk memastikan hanya data yang lengkap yang digunakan dalam analisis. Begitu juga, jika ditemukan data duplikat, data tersebut akan dihapus untuk mencegah pengaruhnya terhadap hasil analisis, yang dapat menyebabkan model menjadi terlalu fokus pada pola tertentu atau memberikan hasil yang tidak akurat.

TABEL 3
MISSING VALUES DAN DATA DUPLIKAT PADA FITUR DATASET

Dari Tabel 3, dapat dilihat bahwa tidak ada fitur yang memiliki missing values, dan juga tidak ditemukan data duplikat pada dataset ini. Ini menunjukkan bahwa dataset sudah dalam kondisi yang baik, dengan data yang lengkap dan unik. Dengan demikian, tidak perlu ada penghapusan data atau penanganan lebih lanjut terkait missing values atau duplikat.
Langkah selanjutnya dalam preprocessing adalah mengklasifikasikan fitur dalam dataset berdasarkan jenisnya, yaitu fitur numerik dan kategorikal. Fitur numerik mencakup variabel yang memiliki nilai numerik yang dapat dihitung dan digunakan dalam perhitungan matematis. Sementara itu, fitur kategorikal berisi variabel yang mengelompokkan data ke dalam kategori atau kelas tertentu. Hasil klasifikasi fitur berdasarkan jenisnya pada Tabel 4.

TABEL 4
KLASIFIKASI FITUR BERDASARKAN JENISNYA

Dari Tabel 4, kita dapat melihat bahwa seluruh fitur kecuali Outcome termasuk dalam kategori numerik. Outcome dianggap sebagai fitur kategorikal karena berisi informasi kelas atau hasil diagnosis diabetes (0 atau 1). Setelah pengklasifikasian ini, langkah selanjutnya adalah melakukan analisis lebih lanjut terhadap fitur numerik, seperti memahami distribusi dan rentang nilainya. Untuk fitur kategorikal, langkah berikutnya adalah memeriksa nilai unik yang terdapat dalam fitur tersebut. Analisis terhadap fitur numerik dan kategorikal telah dilakukan, seperti yang ditampilkan pada Tabel berikut:
1.	Data Numerik
Distribusi dan rentang nilai fitur numerik diperiksa menggunakan statistik deskriptif. Statistik ini memberikan informasi mengenai rata-rata (mean), standar deviasi (std), nilai minimum (min), kuartil (25%, 50%, 75%), dan nilai maksimum (max) untuk setiap fitur numerik. 

TABEL 5
STATISTIK DESKRIPTIF PADA DATA NUMERIK

Berdasarkan analisis statistik deskriptif pada fitur numerik yang dapat dilihat pada Tabel 5, terlihat bahwa terdapat variasi yang signifikan dalam rentang nilai beberapa fitur. Misalnya, fitur "Glucose" memiliki nilai antara 0 hingga 199, dengan rata-rata 120.90 dan deviasi standar 31.97. Sementara itu, fitur "Age" memiliki rentang nilai antara 21 hingga 81, dengan rata-rata 33.24 dan deviasi standar 11.76. Selain itu, fitur "Pregnancies" memiliki nilai maksimum 17 dan rata-rata 3.85, sementara fitur "Insulin" menunjukkan deviasi standar yang sangat tinggi, mencapai 115.24, yang menunjukkan adanya variasi yang besar dalam data. Fitur seperti "SkinThickness" memiliki nilai minimum 0, dan rata-rata yang cukup rendah (20.54), yang bisa mempengaruhi model karena perbedaan skala yang sangat besar antar fitur. Fitur-fitur seperti "BMI" juga menunjukkan variabilitas yang cukup besar, dengan rentang nilai antara 0 hingga 67.1, rata-rata 31.99, dan deviasi standar 7.88. Perbedaan skala yang sangat besar antar fitur ini dapat mempengaruhi kinerja model, karena fitur dengan rentang nilai yang lebih besar cenderung mendominasi pembelajaran model. Oleh karena itu, normalisasi diperlukan untuk menyelaraskan skala dan rentang nilai antar fitur, sehingga setiap fitur dapat berkontribusi secara seimbang dalam model yang dibangun.
2.	Data Kategorikal
Untuk fitur kategorikal, dilakukan pemeriksaan terhadap nilai unik yang ada. Dapat dilihat pada Tabel 6 menunjukkan bahwa fitur Outcome hanya memiliki dua nilai unik, yaitu [0, 1]. 

TABEL 6
NILAI UNIK PADA DATA KATEGORIKAL

Fitur Outcome ini merupakan fitur target dalam dataset yang mengindikasikan apakah seorang pasien mengidap diabetes (1) atau tidak mengidap diabetes (0). Karena hanya memiliki dua nilai unik, fitur ini dapat diperlakukan sebagai fitur kategorikal biner. Dengan hanya dua kelas, fitur Outcome tidak memerlukan normalisasi.
B.	Pembagian Data
Pada tahap ini, akan dilakukan pembagian dataset menjadi dua bagian, yaitu Data Latih dan Data Uji. Pembagian ini dilakukan dengan proporsi 80% untuk data latih dan 20% untuk data uji. Data latih digunakan untuk melatih model, sementara data uji digunakan untuk menguji performa model setelah dilatih. Dataset yang telah dibagi dapat dilihat pada Tabel 7. Data latih terdiri dari 614 baris dan 9 kolom, sementara data uji terdiri dari 154 baris dan 9 kolom. Dengan demikian, dataset sudah siap untuk digunakan dalam tahap pemodelan dan evaluasi selanjutnya.

TABEL 7
PEMBAGIAN DATASET LATIH DAN UJI

C.	Pemilihan Fitur
Setelah pembagian dataset menjadi data latih dan data uji, tahap berikutnya adalah pemilihan fitur. Pemilihan fitur bertujuan untuk mengidentifikasi atribut-atribut mana saja dalam dataset yang memiliki kontribusi paling besar dalam memprediksi target yang diinginkan, dalam hal ini adalah kemungkinan seseorang mengidap diabetes. Untuk melakukan pemilihan fitur, digunakan metode Random Forest, yang memungkinkan kita untuk mengukur tingkat pentingnya setiap fitur dalam menentukan hasil prediksi. Proses deteksi pentingnya fitur dilakukan pada fitur numerik, karena fitur kategorikal seperti Outcome sudah merupakan hasil klasifikasi dan tidak relevan untuk diukur pentingnya menggunakan metode ini. Feature importance yang diperoleh dari model Random Forest hanya dihitung berdasarkan data latih, karena model dilatih menggunakan data tersebut. Namun, penghapusan fitur yang dianggap tidak relevan harus diterapkan secara konsisten pada kedua dataset, baik data latih maupun data uji, agar model yang dievaluasi tidak terpengaruh oleh fitur yang tidak memberikan kontribusi signifikan terhadap hasil prediksi.

TABEL 8
FEATURE IMPORTANCE

Gambar 2. Feature Importance Plot

Berdasarkan analisis feature importance yang ditunjukkan dalam Gambar 2 dan Tabel 8, beberapa fitur memiliki kontribusi yang lebih besar dibandingkan yang lain. Fitur Glucose, BMI, dan Age memiliki nilai penting yang jauh lebih tinggi dibandingkan fitur lainnya. Sebaliknya, fitur seperti SkinThickness, Insulin, Pregnancies, dan BloodPressure menunjukkan nilai penting yang relatif kecil. Misalnya, SkinThickness (0.065646) dan Insulin (0.076122) memiliki nilai penting yang sangat rendah, yang menunjukkan bahwa keduanya memberikan kontribusi yang terbatas terhadap prediksi. Fitur Pregnancies (0.076551) dan BloodPressure (0.088134) juga menunjukkan nilai yang rendah, meskipun sedikit lebih tinggi, namun tidak cukup signifikan untuk dipertahankan dalam model. Fitur SkinThickness, Insulin, Pregnancies, dan BloodPressure diputuskan untuk dihapus karena kontribusinya yang sangat kecil terhadap model. Penghapusan fitur-fitur ini akan membantu meningkatkan efisiensi model, mengurangi kemungkinan overfitting, dan memfokuskan model pada fitur-fitur yang lebih relevan, seperti Glucose, BMI, DiabetesPedigreeFunction, dan Age. Setelah fitur-fitur ini dihapus pada data latih, penghapusan fitur yang sama harus dilakukan pada data uji agar model dapat dievaluasi secara konsisten. Hasil dari feature selection ini dapat dilihat pada Tabel 9.

TABEL 9
FITUR YANG TERSISA SETELAH FEATURE SELECTION

D.	Normalisasi
Setelah pembagian data menjadi data training dan testing, data akan dilakukan normalisasi. Data asli dapat dilihat pada Tabel 10 dan 11 yang memberikan gambaran tentang rentang dan variasi nilai pada setiap fitur dalam data training dan data testing sebelum proses normalisasi dilakukan. Dengan melihat data asli ini, dapat lebih jelas dipahami adanya perbedaan skala yang signifikan antar fitur. 
 
TABEL 10
DATA TRAINING SEBELUM DILAKUKAN NORMALISASI
 
Berdasarkan analisis statistik deskriptif pada fitur numerik yang disajikan dalam Tabel 5, setiap fitur menunjukkan rentang nilai yang bervariasi. Beberapa fitur memiliki nilai minimum nol, sementara yang lain memiliki rentang yang jauh lebih besar. Perbedaan skala ini dapat memengaruhi proses pembelajaran model, karena fitur dengan nilai lebih besar cenderung mendominasi. Oleh karena itu, normalisasi diperlukan untuk menyamakan skala dan rentang nilai antar fitur. Selain itu, berdasarkan pemeriksaan nilai unik pada fitur kategorikal di Tabel 6, fitur Outcome hanya memiliki dua nilai, yaitu 0 dan 1. Karena hanya memiliki dua kelas, fitur ini termasuk dalam kategori biner sehingga tidak memerlukan normalisasi. Dengan demikian, normalisasi akan diterapkan pada semua fitur kecuali Outcome. Proses normalisasi akan diterapkan pada data training dan testing. Selanjutnya, akan dibahas lebih lanjut mengenai detail metode normalisasi yang diterapkan pada data ini:
1.	Min-Max Scaling
Min-Max Scaling menormalisasi data dengan mengubah nilai fitur sehingga berada dalam rentang yang seragam, yaitu antara 0 hingga 1. Proses ini dilakukan dengan menghitung nilai minimum dan maksimum dari data training, kemudian menggunakan nilai tersebut untuk menyesuaikan skala fitur ke rentang tertentu, seperti 0 hingga 1. Dengan demikian, fitur yang memiliki rentang nilai besar akan diperkecil, sementara fitur dengan rentang nilai kecil akan diperbesar, tetapi tetap mempertahankan proporsi antar nilai. Pada data testing, transformasi dilakukan menggunakan nilai minimum dan maksimum yang telah dihitung dari data training tanpa melakukan perhitungan ulang. Hasil dari normalisasi ini dapat dilihat pada Tabel 12 untuk data training dan Tabel 13 untuk data testing.
 
TABEL 12
DATA TRAINING SETELAH DILAKUKAN MIN-MAX SCALING

TABEL 13
DATA TESTING SETELAH DILAKUKAN MIN-MAX SCALING

2.	Z-Score (Standard Scaling)
Z-Score Scaling mengubah data dengan cara menstandarisasi setiap fitur sehingga memiliki rata-rata 0 dan deviasi standar 1. Proses Z-Score ini menggunakan nilai mean dan standar deviasi yang dihitung dari data training untuk menstandarkan fitur sehingga memiliki distribusi dengan mean nol dan standar deviasi satu. Parameter ini kemudian diterapkan pada data testing tanpa menghitung ulang statistik baru. Dengan cara ini, data pada data testing akan disesuaikan menggunakan parameter yang diperoleh dari data training, memastikan konsistensi dalam distribusi data. Hasil dari normalisasi ini dapat dilihat pada Tabel 14 untuk data training dan Tabel 15 untuk data testing.
 
TABEL 14
DATA TRAINING SETELAH DILAKUKAN Z-SCORE (STANDARD SCALING)

TABEL 15
DATA TESTING SETELAH DILAKUKAN Z-SCORE (STANDARD SCALING)

3.	Decimal Scaling
Decimal Scaling menyesuaikan skala fitur dengan membagi nilai setiap fitur dengan pangkat sepuluh yang sesuai. Proses Decimal Scaling ini menyesuaikan skala fitur dengan membagi nilai setiap fitur dengan pangkat 10 berdasarkan jumlah digit terbesar dalam dataset. Karena skala ini ditentukan berdasarkan distribusi keseluruhan data, jika hanya dihitung dari data training, ada kemungkinan distribusi data testing berbeda sehingga skala menjadi tidak konsisten. Pembagian ini dilakukan agar nilai-nilai dalam dataset tidak terlalu besar atau kecil, tetapi tetap mempertahankan proporsi relatif antar data. Teknik ini sangat sederhana, karena hanya melibatkan pembagian dengan angka tetap, dan memastikan bahwa distribusi data tetap terjaga dalam rentang yang lebih kecil. Hasil dari normalisasi ini dapat dilihat pada Tabel 16 untuk data training dan Tabel 17 untuk data testing.
 
TABEL 16
DATA TRAINING SETELAH DILAKUKAN DECIMAL SCALING

TABEL 17
DATA TESTING SETELAH DILAKUKAN DECIMAL SCALING
 
E.	Model KNN (K-Nearest Neighbors)
Setelah pemilihan fitur, langkah selanjutnya adalah melatih model KNN (K-Nearest Neighbors). Proses pelatihan akan dilakukan pada dua versi data, yaitu data yang telah dinormalisasi dengan berbagai metode serta data tanpa normalisasi, untuk membandingkan kinerjanya. Pada setiap model KNN akan diuji dengan berbagai nilai k, yaitu 1, 3, 5, 7, 9, dan 11. Nilai k dalam KNN merujuk pada jumlah tetangga terdekat yang digunakan untuk menentukan kelas data yang sedang diuji. Seluruh nilai k tersebut akan digunakan dalam evaluasi untuk mengamati bagaimana performa model berubah seiring variasi jumlah tetangga, baik pada data yang dinormalisasi maupun yang tidak.

F.	Evaluasi
Setelah model KNN dilatih pada data tanpa normalisasi dan data yang dinormalisasi dengan berbagai metode, tahap selanjutnya adalah mengevaluasi performa masing-masing model. Evaluasi dilakukan menggunakan enam metrik utama, yaitu akurasi, precision, recall, F1-score, specificity, dan ROC AUC. Metrik-metrik ini dipilih karena mampu memberikan gambaran menyeluruh mengenai kekuatan dan kelemahan model, termasuk kemampuannya dalam mengklasifikasikan data positif dan negatif secara tepat. Pengujian dilakukan pada setiap nilai K (1, 3, 5, 7, 9, dan 11) untuk mengamati stabilitas dan sensitivitas model terhadap variasi jumlah tetangga terdekat. Hasil evaluasi performa model KNN berdasarkan kombinasi nilai K dan metode normalisasi dapat dilihat pada Tabel 18.
 
TABEL 18
HASIL EVALUASI PERFORMA MODEL KNN BERDASARKAN METODE NORMALISASI DAN NILAI K

Pada model K-Nearest Neighbors (KNN) tanpa penerapan teknik normalisasi, performa model menunjukkan hasil yang kurang optimal jika dibandingkan dengan skenario lainnya. Akurasi tertinggi yang diperoleh hanya sebesar 0.7597 pada nilai K = 11, dan hasil ini tidak menunjukkan tren yang konsisten seiring bertambahnya nilai K. Sebagai contoh, akurasi sempat menurun menjadi 0.7273 pada K = 7, yang merupakan angka yang sama dengan saat K = 1. Hal ini menunjukkan bahwa tanpa penyamaan skala antar fitur, model kesulitan melakukan perhitungan jarak secara akurat, sehingga memengaruhi kemampuan klasifikasi. Precision tertinggi hanya mencapai 0.7390 dan mengalami fluktuasi pada beberapa nilai K, yang mengindikasikan bahwa model belum cukup efisien dalam mengklasifikasikan data ke kelas positif. Recall juga relatif rendah, dengan nilai tertinggi sebesar 0.7444, menunjukkan bahwa sebagian data positif tidak berhasil dikenali oleh model. F1-Score, yang mencerminkan keseimbangan antara precision dan recall, hanya mencapai angka maksimal 0.7414, dengan tren performa yang cenderung stagnan. Specificity mencapai nilai terbaik sebesar 0.7980 pada K = 9 dan 11, namun nilai ini belum menunjukkan peningkatan signifikan dibanding metode lainnya. ROC AUC yang diperoleh berada pada angka maksimal 0.7802, yang menandakan bahwa kemampuan model dalam membedakan antara kelas positif dan negatif masih terbatas. Secara keseluruhan, hasil ini menunjukkan bahwa tanpa proses normalisasi, KNN tidak dapat memproses perhitungan jarak secara seimbang, terutama ketika data memiliki fitur dengan skala yang bervariasi, sehingga berdampak negatif terhadap performa klasifikasi.
Penerapan Min-Max Scaling menghasilkan peningkatan performa yang signifikan pada seluruh metrik evaluasi KNN. Akurasi tertinggi tercapai pada nilai K = 7 dengan nilai sebesar 0.8117, yang merupakan angka tertinggi dibanding semua metode yang diuji. Precision meningkat secara konsisten hingga mencapai 0.7946, menunjukkan kemampuan model dalam mengklasifikasikan data positif secara lebih tepat dengan tingkat kesalahan false positive yang lebih rendah. Recall juga mengalami peningkatan signifikan, dengan nilai tertinggi sebesar 0.7970, yang mencerminkan sensitivitas model terhadap data positif yang lebih baik dibandingkan metode lainnya. F1-Score yang tertinggi mencapai angka 0.7958, yang mengindikasikan keseimbangan performa precision dan recall yang optimal. Specificity pun menunjukkan performa yang sangat baik dengan nilai maksimal sebesar 0.8485, menandakan bahwa model berhasil mengidentifikasi data negatif secara akurat. Nilai ROC AUC yang diperoleh mencapai 0.8050, memperlihatkan kemampuan model yang kuat dalam membedakan antara dua kelas secara keseluruhan. Efektivitas Min-Max Scaling berasal dari kemampuannya dalam menyamakan rentang semua fitur ke dalam skala 0 hingga 1, sehingga setiap fitur memiliki pengaruh yang seimbang dalam perhitungan jarak. Dengan demikian, model menjadi lebih stabil, lebih akurat, dan dapat diandalkan untuk berbagai jenis data multivariat yang memiliki skala berbeda.
Normalisasi dengan metode Z-Score atau Standard Scaling juga menunjukkan hasil yang kompetitif dalam meningkatkan performa KNN, meskipun dalam beberapa metrik sedikit berada di bawah Min-Max Scaling. Akurasi tertinggi tercatat sebesar 0.7922 pada K = 7, dan menunjukkan pola yang stabil di berbagai nilai K. Precision maksimal berada pada angka 0.7737, dengan tren yang cukup konsisten dan mengindikasikan kemampuan model dalam menekan false positive secara efektif. Recall juga menunjukkan performa yang baik dengan nilai tertinggi sebesar 0.7586, yang menandakan bahwa model cukup sensitif terhadap data positif. F1-Score mencapai nilai maksimal sebesar 0.7554, mencerminkan keseimbangan yang solid antara precision dan recall. Specificity tertinggi mencapai 0.8384, yang menunjukkan kemampuan model dalam mengenali data negatif secara akurat dan konsisten. Hal yang menonjol dari Z-Score adalah nilai ROC AUC yang tertinggi dibanding metode lainnya, yaitu sebesar 0.8129. Nilai ini mengindikasikan bahwa Z-Score sangat efektif dalam meningkatkan kemampuan model dalam membedakan dua kelas secara global. Z-Score bekerja dengan mengurangi setiap nilai fitur dengan rata-rata dan membaginya dengan standar deviasi, sehingga fitur memiliki distribusi standar yang setara. Pendekatan ini tidak hanya menyetarakan skala, tetapi juga mempertahankan struktur distribusi data, menjadikan Z-Score sangat sesuai untuk data dengan distribusi normal atau mengandung outlier ringan.
Normalisasi menggunakan Decimal Scaling menghasilkan performa yang paling rendah dibandingkan dengan metode normalisasi lainnya maupun kondisi tanpa normalisasi. Akurasi tertinggi yang diperoleh hanya sebesar 0.7403 pada nilai K = 9, dengan tren yang tidak stabil pada nilai K lainnya. Precision maksimum juga hanya mencapai 0.7172, yang menunjukkan bahwa model memiliki keterbatasan dalam mengidentifikasi data positif secara akurat. Hal ini juga tercermin pada nilai recall tertinggi yang sama-sama berada pada angka 0.7172, menandakan bahwa sensitivitas model terhadap data positif belum optimal. F1-Score yang tertinggi tidak menunjukkan perbedaan signifikan karena nilainya tetap sebesar 0.7172, mengindikasikan bahwa keseimbangan antara precision dan recall tidak berhasil dicapai secara efektif. Specificity tertinggi berada pada angka 0.7980, setara dengan hasil terbaik pada kondisi tanpa normalisasi, sehingga tidak menunjukkan adanya peningkatan performa. Nilai ROC AUC tertinggi yang dicapai adalah sebesar 0.7874, masih lebih rendah dibandingkan metode Z-Score maupun Min-Max Scaling. Decimal Scaling bekerja dengan menggeser titik desimal berdasarkan nilai maksimum fitur, tanpa mempertimbangkan distribusi atau penyebaran nilai fitur tersebut. Akibatnya, skala antar fitur tetap tidak seragam dan perhitungan jarak dalam KNN menjadi bias. Oleh karena itu, Decimal Scaling kurang direkomendasikan untuk digunakan pada model klasifikasi berbasis jarak seperti KNN, khususnya saat menangani data multivariat dengan rentang nilai yang beragam.
Uji statistik dilakukan untuk mengetahui apakah perbedaan performa model K-Nearest Neighbors (KNN) yang disebabkan oleh penerapan metode normalisasi bersifat signifikan secara statistik. Pengujian dilakukan menggunakan metode paired t-test dua sisi, dengan batas signifikansi sebesar 0,05. Uji ini membandingkan performa setiap metode normalisasi, yaitu Min-Max Scaling, Z-Score atau Standard Scaling, dan Decimal Scaling, dengan kondisi Tanpa Normalisasi pada enam metrik evaluasi utama yang meliputi Accuracy, Precision, Recall, F1-Score, Specificity, dan ROC AUC. Hasil uji statistik secara lengkap dapat dilihat pada Tabel 19 dan Tabel 20, yang menyajikan nilai t-statistic dan p-value untuk masing-masing perbandingan.
 
TABEL 19
HASIL UJI STATISTIK T-STATISTIC PADA SETIAP METRIK EVALUASI

TABEL 20
HASIL UJI STATISTIK P-VALUE PADA SETIAP METRIK EVALUASI

Hasil pengujian pada metrik Accuracy menunjukkan bahwa Min-Max Scaling menghasilkan perbedaan yang signifikan dibandingkan dengan Tanpa Normalisasi. Hal ini dibuktikan dengan nilai p sebesar 0,01035 yang berada di bawah ambang signifikansi 0,05, sehingga dapat disimpulkan bahwa peningkatan akurasi yang ditimbulkan oleh Min-Max Scaling bukanlah hasil kebetulan semata. Sebaliknya, Z-Score menunjukkan p-value sebesar 0,08363 dan Decimal Scaling menghasilkan p-value sebesar 0,05273, keduanya melebihi ambang batas signifikansi, yang berarti perbedaan yang dihasilkan belum cukup kuat untuk dinyatakan signifikan secara statistik. Metrik Precision juga memperlihatkan pola serupa, di mana Min-Max Scaling memberikan hasil signifikan dengan p-value 0,00909. Nilai ini menunjukkan bahwa model dengan Min-Max Scaling secara nyata lebih presisi dalam menghasilkan prediksi positif yang benar. Pada metrik yang sama, Z-Score mencatat p-value sebesar 0,07737, yang menunjukkan bahwa peningkatannya tidak signifikan secara statistik. Sementara itu, Decimal Scaling justru menunjukkan perbedaan signifikan dengan p-value 0,04112, meskipun secara nilai rata-rata performanya masih lebih rendah dibandingkan metode lainnya.
Pada metrik Recall, Min-Max Scaling kembali menunjukkan perbedaan yang signifikan terhadap Tanpa Normalisasi, dengan p-value sebesar 0,01648, yang memperkuat bahwa sensitivitas model terhadap data positif meningkat secara nyata. Z-Score masih belum menunjukkan signifikansi karena p-value sebesar 0,06497, sedangkan Decimal Scaling kembali mencatatkan p-value signifikan sebesar 0,03284. Meskipun demikian, perlu dicatat bahwa peningkatan nilai recall oleh Decimal Scaling tidak disertai oleh peningkatan metrik lain yang konsisten. F1-Score sebagai metrik gabungan dari precision dan recall juga memberikan hasil yang konsisten dengan temuan sebelumnya. Min-Max Scaling menunjukkan p-value sebesar 0,01011 yang menandakan adanya perbedaan signifikan secara statistik, sedangkan Z-Score memiliki p-value sebesar 0,07413, yang berarti peningkatannya belum signifikan. Decimal Scaling dalam hal ini kembali menunjukkan signifikansi dengan p-value sebesar 0,03892, namun performanya secara umum tetap tidak lebih baik dari Min-Max Scaling.
Uji pada metrik Specificity memperlihatkan bahwa hanya Min-Max Scaling yang menghasilkan perbedaan signifikan terhadap Tanpa Normalisasi. Hal ini tercermin dari nilai p sebesar 0,01545 yang lebih kecil dari ambang batas signifikansi. Di sisi lain, Z-Score memiliki p-value sebesar 0,13454 dan Decimal Scaling mencatat p-value sebesar 0,40318. Kedua nilai tersebut menunjukkan bahwa tidak terdapat perbedaan signifikan dalam kemampuan model mengenali kelas negatif ketika menggunakan dua metode tersebut dibandingkan dengan tanpa normalisasi. Terakhir, pada metrik ROC AUC, Min-Max Scaling menunjukkan hasil yang paling kuat secara statistik, dengan p-value yang sangat kecil, yaitu 0,00003. Nilai ini membuktikan bahwa model yang dinormalisasi dengan Min-Max Scaling memiliki kemampuan terbaik dalam membedakan dua kelas secara menyeluruh. Z-Score hampir menunjukkan signifikansi dengan p-value sebesar 0,05603, namun masih sedikit di atas batas yang ditentukan. Sementara itu, Decimal Scaling tidak menunjukkan perbedaan yang signifikan karena p-value yang dicapai sebesar 0,43839, jauh dari batas yang dapat diterima.
Berdasarkan seluruh hasil uji statistik yang telah dilakukan, dapat disimpulkan bahwa Min-Max Scaling merupakan metode normalisasi terbaik secara statistik. Metode ini menghasilkan perbedaan yang signifikan pada keenam metrik evaluasi, yaitu Accuracy, Precision, Recall, F1-Score, Specificity, dan ROC AUC, sehingga peningkatan performa yang diperoleh dapat dianggap valid secara ilmiah dan bukan hasil fluktuasi acak. Z-Score, meskipun secara performa rata-rata menghasilkan nilai tinggi, tidak ada satu pun metrik yang menunjukkan signifikansi berdasarkan uji statistik, sehingga efektivitasnya belum sepenuhnya terkonfirmasi secara matematis. Di sisi lain, Decimal Scaling memang menunjukkan signifikansi pada beberapa metrik seperti Precision, Recall, dan F1-Score, namun performa absolutnya tetap berada di bawah Min-Max Scaling dan Z-Score, serta tidak menunjukkan konsistensi pada metrik lainnya. Dengan demikian, untuk meningkatkan performa KNN secara signifikan dan menyeluruh, Min-Max Scaling dapat direkomendasikan sebagai metode normalisasi yang paling efektif dan terbukti secara statistik.
